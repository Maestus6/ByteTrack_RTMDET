{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fj9YcAnsT4B_"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "09b_0FAnUa9y"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2dwGkL6u1JSi"
      },
      "outputs": [],
      "source": [
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGB')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ghUlAJzKSjFT"
      },
      "outputs": [],
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kY4tmZkWMpsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89baf79c-125a-49f8-db4d-21604d024c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install torch==1.13 torchvision --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mrXibL6LHzh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce058815-7f9d-4130-8120-7444f0860448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m973.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for yolox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cython_bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip3 install yolox@git+https://github.com/braiansmarzaro/ByteTrack.git loguru thop lap cython_bbox --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install cython 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI' --quiet"
      ],
      "metadata": {
        "id": "JEgp0XVFjDoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f289b8-c45c-4c5c-d982-ed67eefc0678"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iEzbf7bdSsLa"
      },
      "outputs": [],
      "source": [
        "class ByteTrackerArguments:\n",
        "    def __init__(self, *args):\n",
        "        self.track_thresh, self.track_buffer, self.match_thresh = args\n",
        "        self.mot20 = True\n",
        "\n",
        "args = ByteTrackerArguments(0.50, 25, 0.80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yDrEBBXtWQk0"
      },
      "outputs": [],
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker\n",
        "\n",
        "tracker = BYTETracker(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kPbSan2rXOaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c96455-bd53-4354-878b-83bc81c816be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.0 which is incompatible.\n",
            "yfinance 0.2.37 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install -U openmim --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FUeL-CZpMbK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dea072-1175-4539-cf82-a4d34e73361b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 38019, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/102)\u001b[K\rremote: Counting objects:   1% (2/102)\u001b[K\rremote: Counting objects:   2% (3/102)\u001b[K\rremote: Counting objects:   3% (4/102)\u001b[K\rremote: Counting objects:   4% (5/102)\u001b[K\rremote: Counting objects:   5% (6/102)\u001b[K\rremote: Counting objects:   6% (7/102)\u001b[K\rremote: Counting objects:   7% (8/102)\u001b[K\rremote: Counting objects:   8% (9/102)\u001b[K\rremote: Counting objects:   9% (10/102)\u001b[K\rremote: Counting objects:  10% (11/102)\u001b[K\rremote: Counting objects:  11% (12/102)\u001b[K\rremote: Counting objects:  12% (13/102)\u001b[K\rremote: Counting objects:  13% (14/102)\u001b[K\rremote: Counting objects:  14% (15/102)\u001b[K\rremote: Counting objects:  15% (16/102)\u001b[K\rremote: Counting objects:  16% (17/102)\u001b[K\rremote: Counting objects:  17% (18/102)\u001b[K\rremote: Counting objects:  18% (19/102)\u001b[K\rremote: Counting objects:  19% (20/102)\u001b[K\rremote: Counting objects:  20% (21/102)\u001b[K\rremote: Counting objects:  21% (22/102)\u001b[K\rremote: Counting objects:  22% (23/102)\u001b[K\rremote: Counting objects:  23% (24/102)\u001b[K\rremote: Counting objects:  24% (25/102)\u001b[K\rremote: Counting objects:  25% (26/102)\u001b[K\rremote: Counting objects:  26% (27/102)\u001b[K\rremote: Counting objects:  27% (28/102)\u001b[K\rremote: Counting objects:  28% (29/102)\u001b[K\rremote: Counting objects:  29% (30/102)\u001b[K\rremote: Counting objects:  30% (31/102)\u001b[K\rremote: Counting objects:  31% (32/102)\u001b[K\rremote: Counting objects:  32% (33/102)\u001b[K\rremote: Counting objects:  33% (34/102)\u001b[K\rremote: Counting objects:  34% (35/102)\u001b[K\rremote: Counting objects:  35% (36/102)\u001b[K\rremote: Counting objects:  36% (37/102)\u001b[K\rremote: Counting objects:  37% (38/102)\u001b[K\rremote: Counting objects:  38% (39/102)\u001b[K\rremote: Counting objects:  39% (40/102)\u001b[K\rremote: Counting objects:  40% (41/102)\u001b[K\rremote: Counting objects:  41% (42/102)\u001b[K\rremote: Counting objects:  42% (43/102)\u001b[K\rremote: Counting objects:  43% (44/102)\u001b[K\rremote: Counting objects:  44% (45/102)\u001b[K\rremote: Counting objects:  45% (46/102)\u001b[K\rremote: Counting objects:  46% (47/102)\u001b[K\rremote: Counting objects:  47% (48/102)\u001b[K\rremote: Counting objects:  48% (49/102)\u001b[K\rremote: Counting objects:  49% (50/102)\u001b[K\rremote: Counting objects:  50% (51/102)\u001b[K\rremote: Counting objects:  51% (53/102)\u001b[K\rremote: Counting objects:  52% (54/102)\u001b[K\rremote: Counting objects:  53% (55/102)\u001b[K\rremote: Counting objects:  54% (56/102)\u001b[K\rremote: Counting objects:  55% (57/102)\u001b[K\rremote: Counting objects:  56% (58/102)\u001b[K\rremote: Counting objects:  57% (59/102)\u001b[K\rremote: Counting objects:  58% (60/102)\u001b[K\rremote: Counting objects:  59% (61/102)\u001b[K\rremote: Counting objects:  60% (62/102)\u001b[K\rremote: Counting objects:  61% (63/102)\u001b[K\rremote: Counting objects:  62% (64/102)\u001b[K\rremote: Counting objects:  63% (65/102)\u001b[K\rremote: Counting objects:  64% (66/102)\u001b[K\rremote: Counting objects:  65% (67/102)\u001b[K\rremote: Counting objects:  66% (68/102)\u001b[K\rremote: Counting objects:  67% (69/102)\u001b[K\rremote: Counting objects:  68% (70/102)\u001b[K\rremote: Counting objects:  69% (71/102)\u001b[K\rremote: Counting objects:  70% (72/102)\u001b[K\rremote: Counting objects:  71% (73/102)\u001b[K\rremote: Counting objects:  72% (74/102)\u001b[K\rremote: Counting objects:  73% (75/102)\u001b[K\rremote: Counting objects:  74% (76/102)\u001b[K\rremote: Counting objects:  75% (77/102)\u001b[K\rremote: Counting objects:  76% (78/102)\u001b[K\rremote: Counting objects:  77% (79/102)\u001b[K\rremote: Counting objects:  78% (80/102)\u001b[K\rremote: Counting objects:  79% (81/102)\u001b[K\rremote: Counting objects:  80% (82/102)\u001b[K\rremote: Counting objects:  81% (83/102)\u001b[K\rremote: Counting objects:  82% (84/102)\u001b[K\rremote: Counting objects:  83% (85/102)\u001b[K\rremote: Counting objects:  84% (86/102)\u001b[K\rremote: Counting objects:  85% (87/102)\u001b[K\rremote: Counting objects:  86% (88/102)\u001b[K\rremote: Counting objects:  87% (89/102)\u001b[K\rremote: Counting objects:  88% (90/102)\u001b[K\rremote: Counting objects:  89% (91/102)\u001b[K\rremote: Counting objects:  90% (92/102)\u001b[K\rremote: Counting objects:  91% (93/102)\u001b[K\rremote: Counting objects:  92% (94/102)\u001b[K\rremote: Counting objects:  93% (95/102)\u001b[K\rremote: Counting objects:  94% (96/102)\u001b[K\rremote: Counting objects:  95% (97/102)\u001b[K\rremote: Counting objects:  96% (98/102)\u001b[K\rremote: Counting objects:  97% (99/102)\u001b[K\rremote: Counting objects:  98% (100/102)\u001b[K\rremote: Counting objects:  99% (101/102)\u001b[K\rremote: Counting objects: 100% (102/102)\u001b[K\rremote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 38019 (delta 38), reused 67 (delta 34), pack-reused 37917\u001b[K\n",
            "Receiving objects: 100% (38019/38019), 63.31 MiB | 16.72 MiB/s, done.\n",
            "Resolving deltas: 100% (26187/26187), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/open-mmlab/mmdetection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TvyNiot0Qdrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf13f51a-991a-4bb4-aa74-54889bce4e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!mim install \"mmengine\" \"mmcv-full\" \"mmdet\" --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1rAPT_HZPDjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0232ac-b5ba-4037-cd17-847af267d6c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-13 19:40:23--  https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.246.20.217, 47.246.20.218, 47.246.20.225, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.246.20.217|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57532893 (55M) [application/octet-stream]\n",
            "Saving to: ‘/content/checkpoint.pth’\n",
            "\n",
            "/content/checkpoint 100%[===================>]  54.87M  16.1MB/s    in 4.0s    \n",
            "\n",
            "2024-04-13 19:40:28 (13.8 MB/s) - ‘/content/checkpoint.pth’ saved [57532893/57532893]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/checkpoint.pth https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1nkSnkbkk4cC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "4e6a4452-4e0f-43cf-ca5a-d3360db82961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: /content/checkpoint.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML =\n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "\n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "\n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "\n",
              "      return {'create': preShow - preCreate,\n",
              "              'show': preCapture - preShow,\n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not track the person\n",
            "Could not track the person\n",
            "\u001b[92mMove right by 0.01\u001b[0m and \u001b[91mMove up by 77.56\u001b[0m\n",
            "\u001b[92mMove right by 11.34\u001b[0m and \u001b[91mMove up by 83.88\u001b[0m\n",
            "\u001b[92mMove left by 10.14\u001b[0m and \u001b[91mMove down by 3.7\u001b[0m\n",
            "\u001b[92mMove left by 91.2\u001b[0m and \u001b[91mMove down by 1.66\u001b[0m\n",
            "\u001b[92mMove left by 163.48\u001b[0m and \u001b[91mMove down by 2.06\u001b[0m\n",
            "\u001b[92mMove left by 163.9\u001b[0m and \u001b[91mMove down by 2.16\u001b[0m\n",
            "\u001b[92mMove left by 124.48\u001b[0m and \u001b[91mMove down by 1.7\u001b[0m\n",
            "\u001b[92mMove left by 138.67\u001b[0m and \u001b[91mMove down by 2.84\u001b[0m\n",
            "\u001b[92mMove left by 15.79\u001b[0m and \u001b[91mMove up by 9.52\u001b[0m\n",
            "\u001b[92mMove right by 90.76\u001b[0m and \u001b[91mMove down by 2.19\u001b[0m\n",
            "\u001b[92mMove right by 128.62\u001b[0m and \u001b[91mMove down by 1.91\u001b[0m\n",
            "\u001b[92mMove right by 135.76\u001b[0m and \u001b[91mMove up by 1.61\u001b[0m\n",
            "Could not track the person\n",
            "\u001b[92mMove right by 104.58\u001b[0m and \u001b[91mMove down by 1.94\u001b[0m\n",
            "\u001b[92mMove right by 55.16\u001b[0m and \u001b[91mMove down by 0.74\u001b[0m\n",
            "\u001b[92mMove right by 87.22\u001b[0m and \u001b[91mMove down by 1.41\u001b[0m\n",
            "\u001b[92mMove right by 97.35\u001b[0m and \u001b[91mMove down by 3.96\u001b[0m\n",
            "Could not track the person\n",
            "Could not track the person\n",
            "Could not track the person\n",
            "Could not track the person\n",
            "Could not track the person\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from mmdet.apis import inference_detector, init_detector\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = init_detector(\"/content/rtmdet.py\", \"/content/checkpoint.pth\", device=device)\n",
        "js = video_stream()\n",
        "label_html = 'Capturing...'\n",
        "image_html = ''\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, image_html)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    result = inference_detector(model, img)\n",
        "\n",
        "    predicted_bboxes = result.pred_instances.bboxes\n",
        "    predicted_scores = result.pred_instances.scores\n",
        "    predicted_labels = result.pred_instances.labels\n",
        "\n",
        "    filtered_bboxes = []\n",
        "    filtered_scores = []\n",
        "    for box, label, score in zip(predicted_bboxes, predicted_labels, predicted_scores):\n",
        "        if label == 0 and score > 0.60:\n",
        "            filtered_bboxes.append(box.cpu().numpy())\n",
        "            filtered_scores.append(score.cpu().numpy())\n",
        "\n",
        "    max_bbox = None\n",
        "    max_score = None\n",
        "    max_area = 0\n",
        "    for box in filtered_bboxes:\n",
        "        area = (box[2] - box[0]) * (box[3] - box[1])\n",
        "        if area > max_area:\n",
        "            max_bbox = box\n",
        "            max_area = area\n",
        "            max_score = filtered_scores[filtered_bboxes.index(box)]\n",
        "\n",
        "\n",
        "    try:\n",
        "        dets = [(max_bbox[0], max_bbox[1], max_bbox[2], max_bbox[3], max_score)]\n",
        "    except:\n",
        "        print(\"Could not track the person\")\n",
        "        continue\n",
        "\n",
        "    online_targets = tracker.update(np.array(dets), img.shape, img.shape)\n",
        "    tracked_bbox = online_targets[0].tlbr\n",
        "    tracked_id = online_targets[0].track_id\n",
        "\n",
        "    if tracked_bbox.shape[0] == 0:\n",
        "        print(\"No person was detected\")\n",
        "        continue\n",
        "    else:\n",
        "        cv2.rectangle(img, (int(tracked_bbox[0]), int(tracked_bbox[1])), (int(tracked_bbox[2]), int(tracked_bbox[3])), (0, 255, 0), 2)\n",
        "        cv2.putText(img, f\"ID: {tracked_id}\", (int(tracked_bbox[0]), int(tracked_bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        image_html = bbox_to_bytes(img)\n",
        "\n",
        "    image_center = (img.shape[1] / 2, img.shape[0] / 2)\n",
        "    bbox_center_x = max_bbox[0] + (max_bbox[2] - max_bbox[0]) / 2\n",
        "    bbox_center_y = max_bbox[1] + (max_bbox[3] - max_bbox[1]) / 2\n",
        "\n",
        "    message = \"\"\n",
        "    if bbox_center_x > image_center[0]:\n",
        "        message += \"\\033[92mMove left by {}\\033[0m and \".format(round(bbox_center_x - image_center[0], 2))\n",
        "    elif bbox_center_x < image_center[0]:\n",
        "        message += \"\\033[92mMove right by {}\\033[0m and \".format(round(image_center[0] - bbox_center_x, 2))\n",
        "    if bbox_center_y > image_center[1]:\n",
        "        message += \"\\033[91mMove up by {}\\033[0m\".format(round(bbox_center_y - image_center[1], 2))\n",
        "    elif bbox_center_y < image_center[1]:\n",
        "        message += \"\\033[91mMove down by {}\\033[0m\".format(round(image_center[1] - bbox_center_y, 2))\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEsxr6X30gYX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}